{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4145404-42af-435e-aaba-1e137522414f",
   "metadata": {},
   "source": [
    "# **Source**:\n",
    "\n",
    "https://www.kaggle.com/datasets/manjitbaishya001/airbnb-new-york-jan-2024?select=detailed_reviews.csv, sourced from Airbnb Description: Airbnb\n",
    "data from New York focussing on listings, locations, and user reviews of\n",
    "locations\n",
    "\n",
    "# **What is the Dataset about?**:\n",
    "\n",
    "This dataset contains listings of Airbnbs in New York, listing features such as what type of housing it is (Rental Unit, Loft, etc.) and the price of the Airbnb. Note that there are several rows with missing values in the price column, which are dealt with during Data Preprocessing. Other features include the name of the host, neighbourhood group, neighbourhood, latitude, longitude, minimum nights to stay, number of reviews about the establishment, the date of the last review, and reviews per month. These features can be used to estimate what an accurate valuation of the Airbnb might be.\n",
    "\n",
    "There is also a dataset with detailed reviews for each Airbnb, which can be used to evaluate the quality of the listing based on user experiences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4a1a8",
   "metadata": {},
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ff0f1-e35f-4035-9b63-0ec516e7ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "# importing dataset and organizing\n",
    "listings_df = pd.read_csv(\"../dataset/listings.csv\")\n",
    "\n",
    "# dropping all listings with a NA price as the percentage of NAs is more than 5%\n",
    "# and imputation on a feature as complex as a listing price seems unnecessary\n",
    "# given the quanitity of listings that do have an associated price\n",
    "listings_df = listings_df.dropna(subset=['price'])\n",
    "\n",
    "# all values are in the correct format\n",
    "print(\"Data Types: \", list(listings_df.dtypes))\n",
    "\n",
    "\n",
    "print(3*\"\\n\", \"Dataframe:\")\n",
    "\n",
    "listings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be98b8",
   "metadata": {},
   "source": [
    "# **Data exploration and summary statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962a488",
   "metadata": {},
   "source": [
    "## **Statistical Method #1**\n",
    "\n",
    "**Null Hypothesis ($H_{0}$) :** The neighborhood group of the Airbnb does not have a statistically significant impact on the availability for the Airbnb.\n",
    "\n",
    "**Alternative Hypothesis ($H_{a}$) :** The neighborhood group of the Airbnb has a statistically significant impact on the availability for the Airbnb.\n",
    "\n",
    "**Alpha-Value ($a$) :** 0.05\n",
    "\n",
    "**Confidence level:** 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063737a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Group by neighborhood group and calculate mean availability\n",
    "df_groups = listings_df.groupby('neighbourhood_group')['availability_365'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Convert mean availability to a list\n",
    "mean_availability = df_groups.tolist()\n",
    "\n",
    "# Perform Kruskal-Wallis test to compare mean availability across neighborhood groups\n",
    "statistic, p = kruskal(*[listings_df[listings_df['neighbourhood_group'] == group]['availability_365'] for group in df_groups.index])\n",
    "\n",
    "print(\"Kruskal-Wallis Test Statistic:\", statistic)\n",
    "print(\"P-Value:\", p)\n",
    "print(df_groups)\n",
    "\n",
    "# Plotting the graph\n",
    "df_groups.plot.bar()\n",
    "plt.ylabel('Average Availability (days)')\n",
    "plt.xlabel('Neighbourhood Groups')\n",
    "plt.title('Average Availabilities Across Neighbourhood Groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baea5a7",
   "metadata": {},
   "source": [
    "Since the p-value is lower than the confidence interval, we can reject the null hypothesis. This means that the location has a statistically significant impact on the availability for the Airbnb. The most available Airbnbs are located in Staten Island, and the least available Airbnbs are in Brooklyn.\n",
    "\n",
    "This is important for the machine learning model because the model should take into account that there are disproportionate availabilities based on the location of the Airbnb. The pricing model will weight this as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293c8ed",
   "metadata": {},
   "source": [
    "## **Statistical Method #2**\n",
    "\n",
    "**Null Hypothesis ($H_{0}$) :** The neighbourhoods in Manhattan do not have a statistically significant impact on the mean prices for Entire home/apt units.\n",
    "\n",
    "**Alternative Hypothesis ($H_{a}$) :** The neighbourhoods in Manhattan have a statistically significant impact on the mean prices for Entire home/apt units.\n",
    "\n",
    "**Alpha-Value ($a$) :** 0.05\n",
    "\n",
    "**Confidence level:** 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Filter the dataset to include only listings in Manhattan with 'Entire home/apt' room type\n",
    "df_manhattan = listings_df[(listings_df['neighbourhood_group'] == 'Manhattan') & (listings_df['room_type'] == 'Entire home/apt')]\n",
    "\n",
    "# Group by neighborhood and calculate mean prices for 'Entire home/apt' units\n",
    "df_groups = df_manhattan.groupby('neighbourhood')['price'].mean().sort_values(ascending=False)\n",
    "mean_prices = list(df_groups)\n",
    "\n",
    "# Perform one-way ANOVA test to test for statistically significant differences between the mean prices of neighborhoods\n",
    "statistic, p = f_oneway(*[df_manhattan[df_manhattan['neighbourhood'] == neighborhood]['price'] for neighborhood in df_groups.index])\n",
    "\n",
    "print(\"P-Value:\", p)\n",
    "\n",
    "# Plot the scatter plot\n",
    "plt.scatter(df_groups.index, mean_prices)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Average Price ($)')\n",
    "plt.xlabel('Manhattan Neighbourhoods')\n",
    "plt.title('Average Prices of Entire home/apt units in Manhattan Neighbourhoods')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf6bfe",
   "metadata": {},
   "source": [
    "As the p-value (7.9997e-22) is less than the alpha value of 0.05, we can reject the null hypothesis and conclude that there is a significant difference in the prices of Entire home/apt units between Manhattan neighbourhoods. Tribeca is the most expensive location in Manhattan based on the data provided/present for entire home/apts, with an average price of approximately $595. These findings allude to the fact that New York's neighbourhood groups have a varying price range of entire home/apt units throught their neighbourhoods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c17926",
   "metadata": {},
   "source": [
    "## **Statistical Method #3**\n",
    "\n",
    "**Null Hypothesis ($H_{0}$) :** The number of reviews of an Airbnb does not have a statistically significant impact on the price of the Airbnb.\n",
    "\n",
    "**Alternative Hypothesis ($H_{a}$) :** The number of reviews of an Airbnb has a statistically significant impact on the price of the Airbnb.\n",
    "\n",
    "**Alpha-Value ($a$) :** 0.05\n",
    "\n",
    "**Confidence level:** 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a289db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# using a threshold that listings with a number of reviews of lesser than 50 is\n",
    "# regarded as 'Low' number of reviews and those with higher than 50 is regarded\n",
    "# as 'High' number of reviews.\n",
    "\n",
    "# taking out outliers (only 7 listings have prices higher than 19000 and may\n",
    "# ruin integrity of our dataset)\n",
    "new_df = listings_df[listings_df[\"price\"] < 19000.0]\n",
    "\n",
    "low_df = new_df[new_df['number_of_reviews'] < 50]\n",
    "high_df = new_df[new_df['number_of_reviews'] >= 50]\n",
    "\n",
    "low_prices = low_df['price']\n",
    "high_prices = high_df['price']\n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(low_prices, high_prices)\n",
    "\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"P-value:\", p_value)\n",
    "\n",
    "# plotting the graph\n",
    "sns.scatterplot(data=new_df, x=\"price\", y=\"number_of_reviews\", linewidth = 0.5, palette=\"mako_r\", alpha=1)\n",
    "plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec6717f",
   "metadata": {},
   "source": [
    "The p-value of 1.444e-17 is extremely small, indicating strong evidence against the null hypothesis.\n",
    "\n",
    "Given the very small p-value, much smaller than the typical significance level of 0.05, we reject the null hypothesis. Therefore, we conclude that there is a statistically significant difference in mean prices between the low and high review groups.\n",
    "\n",
    "If there's a significant difference in mean prices between listings with low and high review counts, this finding could have implications for pricing strategy. For example, it might suggest that listings with higher review counts can command higher prices, potentially reflecting greater perceived value among customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a730f8a",
   "metadata": {},
   "source": [
    "# **Initial Conclusions through Exploratory Analysis**\n",
    "\n",
    "Through our exploratory data analysis and basic data cleaning (the data was pretty clean to begin with) we hope to build a machine learning model to predict the price of Airbnb listings based on features such as location, property type, number of bedrooms, amenities, and historical booking data. This could help hosts optimize their pricing strategy and maximize their revenue.\n",
    "\n",
    "Through our aforementioned Hypothesis Testing, we have found correlatory evidence in features provided in the dataset and being able to predict the value of a listing. This provides a positive outlook onto being able to create a Machine Learning pricing model in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69125de7",
   "metadata": {},
   "source": [
    "### imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import requests\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf78212",
   "metadata": {},
   "source": [
    "### model definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b96086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, n_classes):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=4, stride=1, padding=1)\n",
    "\n",
    "    self.fc1 = nn.Linear(8 * 6 * 7, n_classes)\n",
    "    self.fc2 = nn.Linear(n_classes, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = x.unsqueeze(1)\n",
    "    x = self.conv(x)\n",
    "    x = F.relu(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e55b4bb",
   "metadata": {},
   "source": [
    "### train model using train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd7d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# train-test split of the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.7, shuffle=True)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = int(0.1 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "train_set, test_set, val_set = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n",
    "\n",
    "y_train = train_set.pop('price')\n",
    "y_test = test_set.pop('price')\n",
    "y_val = val_set.pop('price')\n",
    "\n",
    "x_train = torch.tensor(train_set, dtype=torch.float32)\n",
    "x_test = torch.tensor(test_set, dtype=torch.float32)\n",
    "x_val = torch.tensor(val_set, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_model = None\n",
    "mse_store = []\n",
    "loss_store = []\n",
    "eval_epochs = 0\n",
    "batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "        bar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "        for start in bar:\n",
    "\n",
    "            # take a batch\n",
    "            X_batch = X_train[start:start+batch_size]\n",
    "            y_batch = y_train[start:start+batch_size]\n",
    "\n",
    "            # forward pass\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "            # backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # print progress\n",
    "            bar.set_postfix(mse=float(loss))\n",
    "\n",
    "    # evaluate accuracy at end of each epoch\n",
    "    model.eval()\n",
    "    y_pred = model(x_val)\n",
    "\n",
    "    eval_epochs += 1\n",
    "\n",
    "    mse = loss_fn(y_pred, y_val)\n",
    "\n",
    "    mse = float(mse)\n",
    "    mse_store.append(mse)\n",
    "    loss_store.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Train Loss: {loss.item()} Eval Loss: {mse}\")\n",
    "\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "# Save your model's weights\n",
    "model.load_state_dict(best_model)\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36670c",
   "metadata": {},
   "source": [
    "### plot training and eval loss values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore model and return best accuracy\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7d2fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(eval_epochs, loss_store, label='Training loss')\n",
    "plt.plot(eval_epochs, mse_store, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35e1864",
   "metadata": {},
   "source": [
    "# testing model on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd377e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from your saved model using torch.load\n",
    "model_state_dict = torch.load(\"./model.pth\")\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 24),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(24, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")\n",
    "\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "# set model to inference mode\n",
    "model.eval()\n",
    "batch_size = 1\n",
    "preds = []\n",
    "\n",
    "test_loader = DataLoader(x_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "  for x in tqdm(test_loader):\n",
    "\n",
    "    y_pred = model(x)\n",
    "\n",
    "    preds.append(y_pred)\n",
    "\n",
    "\n",
    "# Get the true labels for the validation dataset\n",
    "true_y = torch.tensor(y_test)\n",
    "preds = torch.tensor(preds)\n",
    "\n",
    "accuracy = (true_y == preds).float().mean().item()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
